{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMmTvPoFDKpt",
        "outputId": "a346c399-6752-477b-8cbe-7842b27b1854"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#전공 계열별 활동 빈도 높은 feature 추출 코드"
      ],
      "metadata": {
        "id": "KPPd5RhwYfs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 불러오기\n",
        "df1 = pd.read_csv('/content/YP2021_w03_v4 (1).csv')\n",
        "\n",
        "# 사용할 feature 및 grouping 변수 지정\n",
        "\"\"\"\n",
        "features =['y03a415','y03c292','y03c293','y03c297','y03c300','y03c303','y03c304',]\n",
        "features = list(df.columns)\n",
        "group_col = 'y03a413'\n",
        "\"\"\"\n",
        "features =['y03a415','y03c292','y03c293','y03c297','y03c300','y03c303','y03c304']\n",
        "group_col = 'y03a413'   #전공 계열 인코딩 해서 준다고 함\n",
        "\n",
        "# 결과 저장용\n",
        "group_top_features = {}\n",
        "\n",
        "# 계열(또는 학과)별 반복\n",
        "for group, sub in df1.groupby(group_col):\n",
        "    # 각 활동별 빈도(합계) 계산 (1/0 변수 기준)\n",
        "    freq = sub[features].mean().sort_values(ascending=False)\n",
        "    top_n = freq.head(3)   # top 3개\n",
        "    group_top_features[group] = top_n\n",
        "\n",
        "# 보기 쉽게 DataFrame으로 변환\n",
        "top_df = pd.DataFrame(group_top_features)\n",
        "print(top_df)\n",
        "\n",
        "# (옵션) 계열별 Top-3 항목과 빈도 출력\n",
        "for group, top3 in group_top_features.items():\n",
        "    print(f\"\\n[{group}] 상위 3개 활동:\")\n",
        "    print(top3)"
      ],
      "metadata": {
        "id": "7yFMKHOUYgIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23e31b44-97d6-4582-84a0-44caa754723b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         1.0        2.0        3.0        4.0        5.0        6.0        \\\n",
            "y03a415   4.751445   4.859873   4.902941   4.957055   4.979487   4.847826   \n",
            "y03c292   2.919355        NaN   2.953125   3.110390   2.721311   3.083333   \n",
            "y03c297        NaN   2.979381        NaN        NaN        NaN        NaN   \n",
            "y03c300   3.016129   3.170103   3.015625   3.298701   2.754098   3.250000   \n",
            "\n",
            "         7.0        97.0       9090908.0  \n",
            "y03a415   4.954545        5.0        5.0  \n",
            "y03c292        NaN        NaN        5.0  \n",
            "y03c297   2.744898        2.5        NaN  \n",
            "y03c300   3.061224        2.5        5.0  \n",
            "\n",
            "[1.0] 상위 3개 활동:\n",
            "y03a415    4.751445\n",
            "y03c300    3.016129\n",
            "y03c292    2.919355\n",
            "dtype: float64\n",
            "\n",
            "[2.0] 상위 3개 활동:\n",
            "y03a415    4.859873\n",
            "y03c300    3.170103\n",
            "y03c297    2.979381\n",
            "dtype: float64\n",
            "\n",
            "[3.0] 상위 3개 활동:\n",
            "y03a415    4.902941\n",
            "y03c300    3.015625\n",
            "y03c292    2.953125\n",
            "dtype: float64\n",
            "\n",
            "[4.0] 상위 3개 활동:\n",
            "y03a415    4.957055\n",
            "y03c300    3.298701\n",
            "y03c292    3.110390\n",
            "dtype: float64\n",
            "\n",
            "[5.0] 상위 3개 활동:\n",
            "y03a415    4.979487\n",
            "y03c300    2.754098\n",
            "y03c292    2.721311\n",
            "dtype: float64\n",
            "\n",
            "[6.0] 상위 3개 활동:\n",
            "y03a415    4.847826\n",
            "y03c300    3.250000\n",
            "y03c292    3.083333\n",
            "dtype: float64\n",
            "\n",
            "[7.0] 상위 3개 활동:\n",
            "y03a415    4.954545\n",
            "y03c300    3.061224\n",
            "y03c297    2.744898\n",
            "dtype: float64\n",
            "\n",
            "[97.0] 상위 3개 활동:\n",
            "y03a415    5.0\n",
            "y03c300    2.5\n",
            "y03c297    2.5\n",
            "dtype: float64\n",
            "\n",
            "[9090908.0] 상위 3개 활동:\n",
            "y03a415    5.0\n",
            "y03c292    5.0\n",
            "y03c300    5.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#로지스틱 회귀 & 랜덤포레스트"
      ],
      "metadata": {
        "id": "PMyEOrKQYc6l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oD_npay3TJWa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class FeatureImportanceAnalyzer:\n",
        "    def __init__(self, X, y, feature_names):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.feature_names = feature_names\n",
        "        self.lr_model = None\n",
        "        self.rf_model = None\n",
        "\n",
        "    # === 중요도 출력 함수 ===\n",
        "    def print_importance(self, importance, model_name, top_n=5):\n",
        "        series = pd.Series(importance, index=self.feature_names)\n",
        "        series = series.abs().sort_values(ascending=False)\n",
        "        print(f\"\\n[{model_name}] 중요도 TOP {top_n}\")\n",
        "        print(series.head(top_n))\n",
        "        return series.head(top_n)\n",
        "\n",
        "    # === 로지스틱 회귀 ===\n",
        "    def fit_logistic_regression(self, **kwargs):\n",
        "        self.lr_model = LogisticRegression(max_iter=200, **kwargs)\n",
        "        self.lr_model.fit(self.X, self.y)\n",
        "        importance = self.lr_model.coef_[0]\n",
        "        return self.print_importance(importance, \"Logistic Regression\")\n",
        "\n",
        "    # === 랜덤포레스트 ===\n",
        "    def fit_random_forest(self, **kwargs):\n",
        "        self.rf_model = RandomForestClassifier(n_estimators=100, random_state=42, **kwargs)\n",
        "        self.rf_model.fit(self.X, self.y)\n",
        "        importance = self.rf_model.feature_importances_\n",
        "        return self.print_importance(importance, \"Random Forest\")\n",
        "\n",
        "    # === 로지스틱 회귀 하이퍼파라미터 튜닝 ===\n",
        "    def tune_logistic_regression(self, param_grid=None, cv=5, scoring='accuracy'):\n",
        "        if param_grid is None:\n",
        "            param_grid = {\n",
        "                'C': [0.01, 0.1, 1, 10],\n",
        "                'penalty': ['l2'],\n",
        "                'solver': ['lbfgs', 'liblinear'],\n",
        "                'max_iter': [100, 200]\n",
        "            }\n",
        "        grid = GridSearchCV(LogisticRegression(), param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
        "        grid.fit(self.X, self.y)\n",
        "        print(\"\\n[Logistic Regression] Best Params:\", grid.best_params_)\n",
        "        print(\"[Logistic Regression] Best CV Score:\", grid.best_score_)\n",
        "        self.lr_model = grid.best_estimator_\n",
        "        importance = self.lr_model.coef_[0]\n",
        "        return self.print_importance(importance, \"Logistic Regression (Tuned)\")\n",
        "\n",
        "    # === 랜덤포레스트 하이퍼파라미터 튜닝 ===\n",
        "    def tune_random_forest(self, param_grid=None, cv=5, scoring='accuracy'):\n",
        "        if param_grid is None:\n",
        "            param_grid = {\n",
        "                'n_estimators': [100, 200],\n",
        "                'max_depth': [None, 5, 10],\n",
        "                'min_samples_split': [2, 5],\n",
        "                'min_samples_leaf': [1, 2],\n",
        "                'max_features': ['auto', 'sqrt']\n",
        "            }\n",
        "        grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
        "        grid.fit(self.X, self.y)\n",
        "        print(\"\\n[Random Forest] Best Params:\", grid.best_params_)\n",
        "        print(\"[Random Forest] Best CV Score:\", grid.best_score_)\n",
        "        self.rf_model = grid.best_estimator_\n",
        "        importance = self.rf_model.feature_importances_\n",
        "        return self.print_importance(importance, \"Random Forest (Tuned)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- 사용 예시 ----------------\n",
        "df1['취업여부'] = df1['y01c101a'].notnull().astype(int)\n",
        "target = df1['취업여부']\n",
        "X = df1[features]\n",
        "y = target\n",
        "\n",
        "#결측치 처리 (예비)\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "# 인스턴스 생성\n",
        "analyzer = FeatureImportanceAnalyzer(X, y, features)\n",
        "\n",
        "# 모델 학습 및 중요도\n",
        "\n",
        "analyzer.fit_logistic_regression()\n",
        "analyzer.fit_random_forest()\n",
        "\n",
        "\"\"\" *시간 오래걸림*\n",
        "# 하이퍼파라미터 튜닝\n",
        "analyzer.tune_logistic_regression()\n",
        "analyzer.tune_random_forest()\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GQ3BrFenT1B4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "94b59eed-3c97-4204-d8c2-143799d38d3b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Logistic Regression] 중요도 TOP 5\n",
            "y03c300    0.353341\n",
            "y03c297    0.327131\n",
            "y03c304    0.245633\n",
            "y03c303    0.189937\n",
            "y03a415    0.176283\n",
            "dtype: float64\n",
            "\n",
            "[Random Forest] 중요도 TOP 5\n",
            "y03c300    0.217122\n",
            "y03c297    0.196390\n",
            "y03c293    0.160610\n",
            "y03c304    0.144600\n",
            "y03c292    0.142649\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' *시간 오래걸림*\\n# 하이퍼파라미터 튜닝\\nanalyzer.tune_logistic_regression()\\nanalyzer.tune_random_forest()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#같은 전공(계열) & 전공 내 취업자에서 특이치\n",
        "\n",
        "\n",
        "**  전공 내 취업자만 다룬다."
      ],
      "metadata": {
        "id": "MsWoeqh0Y2i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "class HighEarnerByMajorGroupAnalyzer:\n",
        "    def __init__(self, df, salary_col, major_group_col, activity_cols, major_match_score_col, high_percentile=0.6):\n",
        "        self.df = df\n",
        "        self.salary_col = salary_col\n",
        "        self.major_group_col = major_group_col\n",
        "        self.activity_cols = activity_cols\n",
        "        self.major_match_score_col = major_match_score_col  # 일치도 점수 컬럼\n",
        "        self.high_percentile = high_percentile\n",
        "        self.results = []\n",
        "\n",
        "    def _define_high_and_normal(self, sub):\n",
        "        \"\"\"고연봉자/일반자 집단 생성\"\"\"\n",
        "        salary_z = (sub[self.salary_col] - sub[self.salary_col].mean()) / sub[self.salary_col].std()\n",
        "        cutoff = salary_z.quantile(self.high_percentile)\n",
        "        sub = sub.copy()\n",
        "        sub['high_salary'] = (salary_z > cutoff).astype(int)\n",
        "        high = sub[sub['high_salary'] == 1]\n",
        "        normal = sub[sub['high_salary'] == 0]\n",
        "        return high, normal\n",
        "\n",
        "    def _compare_activities(self, high, normal):\n",
        "        \"\"\"각 활동별 고연봉자 vs 일반자 차이와 유의성 검정\"\"\"\n",
        "        stats = {}\n",
        "        for feat in self.activity_cols:\n",
        "            try:\n",
        "                mean_high = high[feat].mean()\n",
        "                mean_normal = normal[feat].mean()\n",
        "                diff = mean_high - mean_normal\n",
        "                # 이진형(0/1)\n",
        "                if set(high[feat].dropna().unique()) <= {0,1} and set(normal[feat].dropna().unique()) <= {0,1}:\n",
        "                    count = np.array([high[feat].sum(), normal[feat].sum()])\n",
        "                    nobs = np.array([len(high), len(normal)])\n",
        "                    _, p = proportions_ztest(count, nobs)\n",
        "                # 수치형\n",
        "                else:\n",
        "                    _, p = ttest_ind(high[feat], normal[feat], nan_policy='omit')\n",
        "            except Exception:\n",
        "                mean_high, mean_normal, diff, p = np.nan, np.nan, np.nan, np.nan\n",
        "            stats[feat] = {\n",
        "                '고연봉평균': mean_high,\n",
        "                '일반평균': mean_normal,\n",
        "                '차이': diff,\n",
        "                'p_value': p\n",
        "            }\n",
        "        return stats\n",
        "\n",
        "    def analyze(self, min_group=10, print_example_n=2, pvalue_threshold=0.4, diff_threshold=0.3):\n",
        "        self.results = []\n",
        "        # 1. 자기전공-일치도 점수 3 이상만 필터\n",
        "        df_case = self.df[(self.df[self.major_match_score_col] >= 3) & (self.df[self.major_match_score_col] <= 5)]\n",
        "        print(f\"\\n========== [자기전공-일치도 3 이상 5이하 그룹 분석] ==========\")\n",
        "        # 2. 전공계열별 반복\n",
        "        for major, sub in df_case.groupby(self.major_group_col):\n",
        "            if len(sub) < min_group:\n",
        "                continue\n",
        "            # 3. 고연봉자/일반자 집단 생성\n",
        "            high, normal = self._define_high_and_normal(sub)\n",
        "            if len(high) < 2 or len(normal) < 2:\n",
        "                continue\n",
        "            # 4. 활동별 차이/유의성 검정\n",
        "            stats = self._compare_activities(high, normal)\n",
        "            # 5. 고연봉자에서만 특이하게 큰 활동 마킹\n",
        "            special_feats = {feat: v for feat, v in stats.items() if\n",
        "                             v['p_value'] is not None and v['p_value'] < pvalue_threshold and abs(v['차이']) > diff_threshold}\n",
        "            result = {\n",
        "                '전공계열': major,\n",
        "                '고연봉자수': len(high),\n",
        "                '일반자수': len(normal),\n",
        "                '전체차이통계': stats,\n",
        "                '고연봉자특이활동': special_feats\n",
        "            }\n",
        "            self.results.append(result)\n",
        "        # 6. 대표결과 출력\n",
        "        for res in self.results[:print_example_n]:\n",
        "            print(f\"\\n전공계열: {res['전공계열']} | 고연봉자:{res['고연봉자수']} / 일반자:{res['일반자수']}\")\n",
        "            print(\"▶ 고연봉자에서만 유의하게 특이한 활동 (차이+유의성):\")\n",
        "            for feat, v in res['고연봉자특이활동'].items():\n",
        "                print(f\"{feat}: 고연봉자평균={v['고연봉평균']:.2f}, 일반평균={v['일반평균']:.2f}, 차이={v['차이']:.2f}, p={v['p_value']:.3f}\")\n",
        "        return self.results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Q_ut0dXzKLL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- 사용 예시 ---------\n",
        "\n",
        "salary_col = 'y01d302_left' #[첫] 첫직장 입사시 연봉 (만원)\n",
        "major_group_col = 'y03a413' #전공 계열\n",
        "activity_cols = ['y03a415','y03c292','y03c293','y03c297','y03c300','y03c303','y03c304'] #features\n",
        "major_match_score_col = 'y03c245' #자기전공-일치도\n",
        "analyzer = HighEarnerByMajorGroupAnalyzer(df1, salary_col, major_group_col, activity_cols, major_match_score_col)\n",
        "results = analyzer.analyze(min_group=10, print_example_n=2, pvalue_threshold=0.2, diff_threshold=0.15)"
      ],
      "metadata": {
        "id": "qpAbwNBrLSd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d79a4a51-0ca3-40f3-f227-09ba2c05dcce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== [자기전공-일치도 3 이상 5이하 그룹 분석] ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "전공계열: 1.0 | 고연봉자:4 / 일반자:30\n",
            "▶ 고연봉자에서만 유의하게 특이한 활동 (차이+유의성):\n",
            "y03c303: 고연봉자평균=1.75, 일반평균=2.73, 차이=-0.98, p=0.085\n",
            "y03c304: 고연봉자평균=1.75, 일반평균=2.73, 차이=-0.98, p=0.085\n",
            "\n",
            "전공계열: 2.0 | 고연봉자:14 / 일반자:95\n",
            "▶ 고연봉자에서만 유의하게 특이한 활동 (차이+유의성):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n",
            "/usr/local/lib/python3.11/dist-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#같은 직무에서 특이치\n",
        "\n",
        "\n",
        "**  전공 취업자와 비전공취업자 따로 분석"
      ],
      "metadata": {
        "id": "t39SGooiy8Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "class HighEarnerByMajorMatchAnalyzer:\n",
        "    def __init__(self, df, salary_col, job_col, activity_cols, major_match_col, high_percentile=0.9):\n",
        "        self.df = df\n",
        "        self.salary_col = salary_col\n",
        "        self.job_col = job_col\n",
        "        self.activity_cols = activity_cols\n",
        "        self.major_match_col = major_match_col\n",
        "        self.high_percentile = high_percentile\n",
        "        self.results = []\n",
        "\n",
        "    def _define_high_and_normal(self, sub):\n",
        "        salary_z = (sub[self.salary_col] - sub[self.salary_col].mean()) / sub[self.salary_col].std()\n",
        "        cutoff = salary_z.quantile(self.high_percentile)\n",
        "        sub = sub.copy()\n",
        "        sub['high_salary'] = (salary_z > cutoff).astype(int)\n",
        "        high = sub[sub['high_salary'] == 1]\n",
        "        normal = sub[sub['high_salary'] == 0]\n",
        "        return high, normal\n",
        "\n",
        "    def _compare_activities(self, high, normal):\n",
        "        stats = {}\n",
        "        for feat in self.activity_cols:\n",
        "            try:\n",
        "                mean_high = high[feat].mean()\n",
        "                mean_normal = normal[feat].mean()\n",
        "                diff = mean_high - mean_normal\n",
        "                # 이진형(0/1)\n",
        "                if set(high[feat].dropna().unique()) <= {0,1} and set(normal[feat].dropna().unique()) <= {0,1}:\n",
        "                    count = np.array([high[feat].sum(), normal[feat].sum()])\n",
        "                    nobs = np.array([len(high), len(normal)])\n",
        "                    _, p = proportions_ztest(count, nobs)\n",
        "                # 수치형\n",
        "                else:\n",
        "                    _, p = ttest_ind(high[feat], normal[feat], nan_policy='omit')\n",
        "            except Exception:\n",
        "                mean_high, mean_normal, diff, p = np.nan, np.nan, np.nan, np.nan\n",
        "            stats[feat] = {\n",
        "                '고연봉평균': mean_high,\n",
        "                '일반평균': mean_normal,\n",
        "                '차이': diff,\n",
        "                'p_value': p\n",
        "            }\n",
        "        return stats\n",
        "\n",
        "    def analyze(self, min_group=10, print_example_n=2, pvalue_threshold=0.05, diff_threshold=0.1):\n",
        "        self.results = []\n",
        "        # 정확하게 1,2=불일치, 3,4,5=일치\n",
        "        group_cases = [\n",
        "            {\"label\": \"전공일치\", \"condition\": lambda df: df[self.major_match_col].isin([3, 4, 5])},\n",
        "            {\"label\": \"전공불일치\", \"condition\": lambda df: df[self.major_match_col].isin([1, 2])},\n",
        "        ]\n",
        "        for group in group_cases:\n",
        "            group_name = group[\"label\"]\n",
        "            df_case = group[\"condition\"](self.df)\n",
        "            df_group = self.df[df_case]\n",
        "            print(f\"\\n========== [{group_name} 그룹 분석] ==========\")\n",
        "            # 2. 직무코드별 반복\n",
        "            for job, sub in df_group.groupby(self.job_col):\n",
        "                if len(sub) < min_group:\n",
        "                    continue\n",
        "                high, normal = self._define_high_and_normal(sub)\n",
        "                if len(high) < 2 or len(normal) < 2:\n",
        "                    continue\n",
        "                stats = self._compare_activities(high, normal)\n",
        "                special_feats = {feat: v for feat, v in stats.items() if\n",
        "                                 v['p_value'] is not None and v['p_value'] < pvalue_threshold and abs(v['차이']) > diff_threshold}\n",
        "                result = {\n",
        "                    '전공일치여부': group_name,\n",
        "                    '직무코드': job,\n",
        "                    '고연봉자수': len(high),\n",
        "                    '일반자수': len(normal),\n",
        "                    '전체차이통계': stats,\n",
        "                    '고연봉자특이활동': special_feats\n",
        "                }\n",
        "                self.results.append(result)\n",
        "            # 3. 그룹별 대표결과 출력\n",
        "            group_results = [r for r in self.results if r['전공일치여부'] == group_name]\n",
        "            for res in group_results[:print_example_n]:\n",
        "                print(f\"\\n직무코드: {res['직무코드']} | 고연봉자:{res['고연봉자수']} / 일반자:{res['일반자수']}\")\n",
        "                print(\"▶ 고연봉자에서만 유의하게 특이한 활동 (차이+유의성):\")\n",
        "                for feat, v in res['고연봉자특이활동'].items():\n",
        "                    print(f\"{feat}: 고연봉자평균={v['고연봉평균']:.2f}, 일반평균={v['일반평균']:.2f}, 차이={v['차이']:.2f}, p={v['p_value']:.3f}\")\n",
        "        return self.results\n",
        "\n"
      ],
      "metadata": {
        "id": "3IwjNz7Q70X0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- 사용 예시 ---------\n",
        "\n",
        "salary_col = 'y01d302_left'#[첫] 첫직장 입사시 연봉 (만원)\n",
        "job_col = '직업코드'\n",
        "activity_cols = ['y03a415','y03c292','y03c293','y03c297','y03c300','y03c303','y0c304'] #features\n",
        "major_match_score_col = 'y03c245' #자기전공-일치도\n",
        "analyzer = HighEarnerByMajorMatchAnalyzer(df1, salary_col, job_col, activity_cols, major_match_score_col)\n",
        "results = analyzer.analyze(min_group=10, print_example_n=2, pvalue_threshold=0.05, diff_threshold=0.1)"
      ],
      "metadata": {
        "id": "1dTF-Xo7LQ6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "370710bb-0937-4244-e73a-d9e677cb8563"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-aa7425493c33>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactivity_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'y03a415'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y03c292'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y03c293'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y03c297'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y03c300'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y03c303'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y0c304'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmajor_match_score_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'y03c245'\u001b[0m \u001b[0;31m#자기전공-일치도\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHighEarnerByMajorMatchAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalary_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor_match_score_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_example_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalue_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IRsEAEyEgNeB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}